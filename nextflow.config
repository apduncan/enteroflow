// The matrix to be decomposed
params.matrix = "resources/test_data.tsv"
// Number of random shuffles of matrix
params.n = 2
// Lower and upper bound of ranks to search during rank selection, inclusive
params.ranks = "2,4"
// Number of iterations per rank, on each shuffled matrix
params.rank_iterations = 1
// Max NMF iterations, shared across all tasks
params.nmf_max_iter = 3000
// Regularisation values to search
params.alpha = [0, 0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 5]
// Ranks to search in regularisation
// You may want to set this to a small number of ranks suggested by the 
// initial rank selection step
params.regu_rank = [3, 4]
// Number of randomly initialised decompositions on full matrix
// when getting decompositions for a given rank
params.random_starts = 50

// Random seed
params.seed = 4298

// Output details
params.publish_dir = "output"


profiles {
    conda {
        process.conda = 'env.yaml'
        conda.mamba = true
    }
    slurm {
        // conda stuff
        conda.useMicromamba = true
        // slurm stuff
        process {
            conda = '/path/to/env/'
            executor = 'slurm'
            queue = 'ei-short'
            memory = '1.5GB'
            cpus = 4
            withLabel: largemem {
                // Typically our processes requiring a lot of memory are
                // splitting and merging data, and not very computationally
                // demanding
                queue = 'ei-short'
                memory = '8GB'
                cpus = 2
            }
        }
    }
}

dag.verbose = true