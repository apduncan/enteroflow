{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of NMF bicv for enterosignature regularisation choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import median, mean\n",
    "import json\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important assumption for this notebook is that for each combination of \n",
    "shuffled matrix, rank, alpha value and fold, decomposition is only run once.\n",
    "While currently you could set the nruns parameter to a higher value in \n",
    "`bicv_regu.py`, only the first of the runs will be taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpdir = f\"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if WRITE_OUTPUT is True, output tables will be written\n",
    "\n",
    "WRITE_OUTPUT = True\n",
    "chosen_rank = 2 # This report only carries out analysis for one rank. There\n",
    "# may be more than one rank in the results though.\n",
    "\n",
    "output = inpdir #\"bicv_regu_analysis/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha values for regularisation parameters are set in the script for running bicv. \n",
    "In case they were changed, they need to be changed below too in order to prevent errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0]\n",
    "alphas.extend([2**x for x in range(-5,2)])\n",
    "alphas.extend([5,10,50,100])\n",
    "print(alphas)\n",
    "#print(len(alphas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_evar = inpdir + \"biCV_evar.json\"\n",
    "with open(raw_file_evar, \"r\") as f:\n",
    "    raw_evar = json.load(f)\n",
    "    \n",
    "raw_file_sparsity = inpdir + \"biCV_sparsity.json\"\n",
    "with open(raw_file_sparsity, \"r\") as f:\n",
    "    raw_sparsity = json.load(f)\n",
    "    \n",
    "raw_file_l2norm = inpdir + \"biCV_l2norm.json\"\n",
    "with open(raw_file_l2norm, \"r\") as f:\n",
    "    raw_l2norm = json.load(f)\n",
    "    \n",
    "raw_file_recoerror = inpdir + \"biCV_reco_error.json\"\n",
    "with open(raw_file_recoerror, \"r\") as f:\n",
    "    raw_recoerror = json.load(f)\n",
    "\n",
    "raw_file_rss = inpdir + \"biCV_rss.json\"\n",
    "with open(raw_file_rss, \"r\") as f:\n",
    "    raw_rss = json.load(f)\n",
    "    \n",
    "raw_file_cosine = inpdir + \"biCV_cosine.json\"\n",
    "with open(raw_file_cosine, \"r\") as f:\n",
    "    raw_cosine = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the ranks ranks and alpha values which are in these results\n",
    "ranks = sorted(int(x) for x in raw_evar[0]['0'].keys())\n",
    "alphas = sorted(float(x) for x in raw_evar[0]['0'][str(ranks[0])])\n",
    "(ranks, alphas)\n",
    "if chosen_rank not in ranks:\n",
    "    print(f\"Chosen rank {chosen_rank} not in results, using {ranks[0]} instead\")\n",
    "    chosen_rank = ranks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the above objects is a list of n dictionaries corresponding to the n matrix shuffling performed in bicv.\n",
    "Each dictionary is composed of several levels of dictionaries\n",
    "\n",
    "- First level is the fold of bicv (the 9 submatrices were validation set at some point)\n",
    "- Second level is the rank (number of enterosignatures)\n",
    "- Third level is the regularisation ratio (alpha)\n",
    "- The last level contains the keys A, B, C, D, corresponding to the parts of the matrix during bicv. A is the validation set, D is the set on which the first NMF was performed. B and C are the intermediaries. The values for the validation set A are the ones we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evars = {alpha:[] for alpha in alphas}\n",
    "rss = {alpha:[] for alpha in alphas}\n",
    "recoerror = {alpha:[] for alpha in alphas}\n",
    "cosine = {alpha:[] for alpha in alphas}\n",
    "l2norm = {alpha:[] for alpha in alphas}\n",
    "sparsityH = {alpha:[] for alpha in alphas}\n",
    "sparsityW = {alpha:[] for alpha in alphas}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the dicts of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_evar is a list of dicts\n",
    "for d in raw_evar: #run'th element of the list\n",
    "    # d is a dict of dicts. Its keys are the matrices, subkeys are ranks. subsubkeys are regularisation ratios and subsubsubkeys A, B, C, D submatrices\n",
    "    for mx in d:\n",
    "        for regu in d[mx][str(chosen_rank)]:\n",
    "            evars[float(regu)].extend(d[mx][str(chosen_rank)][regu][\"A\"])\n",
    "\n",
    "#same idea for all metrics\n",
    "for d in raw_cosine:\n",
    "    for mx in d:\n",
    "        for regu in d[mx][str(chosen_rank)]:\n",
    "            cosine[float(regu)].extend(d[mx][str(chosen_rank)][regu][\"A\"])\n",
    "            \n",
    "for d in raw_rss:\n",
    "    for mx in d:\n",
    "        for regu in d[mx][str(chosen_rank)]:\n",
    "            rss[float(regu)].extend(d[mx][str(chosen_rank)][regu][\"A\"])\n",
    "            \n",
    "for d in raw_recoerror:\n",
    "    for mx in d:\n",
    "        for regu in d[mx][str(chosen_rank)]:\n",
    "            recoerror[float(regu)].extend(d[mx][str(chosen_rank)][regu][\"A\"])\n",
    "\n",
    "for d in raw_l2norm:\n",
    "    for mx in d:\n",
    "        for regu in d[mx][str(chosen_rank)]:\n",
    "            l2norm[float(regu)].extend(d[mx][str(chosen_rank)][regu][\"A\"])\n",
    "\n",
    "for d in raw_sparsity:\n",
    "    for mx in d:\n",
    "        for regu in d[mx][str(chosen_rank)]:\n",
    "            sparsityH[float(regu)].append(d[mx][str(chosen_rank)][regu][\"A\"][0][0])\n",
    "            sparsityW[float(regu)].append(d[mx][str(chosen_rank)][regu][\"A\"][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_OUTPUT:\n",
    "    labels, data = [*zip(*evars.items())]\n",
    "    with open(f\"{output}/evar.tsv\", \"w\") as f:\n",
    "        for i in range(0, len(labels)):\n",
    "            for j in data[i]:\n",
    "                f.write(str(labels[i]) + \"\\t\" + str(j) + \"\\n\")\n",
    "    #\n",
    "    labels, data = [*zip(*cosine.items())]\n",
    "    with open(f\"{output}/cosine.tsv\", \"w\") as f:\n",
    "        for i in range(0, len(labels)):\n",
    "            for j in data[i]:\n",
    "                f.write(str(labels[i]) + \"\\t\" + str(j) + \"\\n\")\n",
    "    #\n",
    "    labels, data = [*zip(*l2norm.items())]\n",
    "    with open(f\"{output}/l2norm.tsv\", \"w\") as f:\n",
    "        for i in range(0, len(labels)):\n",
    "            for j in data[i]:\n",
    "                f.write(str(labels[i]) + \"\\t\" + str(j) + \"\\n\")\n",
    "    #\n",
    "    labels, data = [*zip(*rss.items())]\n",
    "    with open(f\"{output}/rss.tsv\", \"w\") as f:\n",
    "        for i in range(0, len(labels)):\n",
    "            for j in data[i]:\n",
    "                f.write(str(labels[i]) + \"\\t\" + str(j) + \"\\n\")\n",
    "    #\n",
    "    labels, data = [*zip(*recoerror.items())]\n",
    "    with open(f\"{output}/recerror.tsv\", \"w\") as f:\n",
    "        for i in range(0, len(labels)):\n",
    "            for j in data[i]:\n",
    "                f.write(str(labels[i]) + \"\\t\" + str(j) + \"\\n\")\n",
    "    #\n",
    "    labels, data = [*zip(*sparsityH.items())]\n",
    "    with open(f\"{output}/sparsityH.tsv\", \"w\") as f:\n",
    "        for i in range(0, len(labels)):\n",
    "            for j in data[i]:\n",
    "                f.write(str(labels[i]) + \"\\t\" + str(j) + \"\\n\")\n",
    "    #\n",
    "    labels, data = [*zip(*sparsityW.items())]\n",
    "    with open(f\"{output}/sparsityW.tsv\", \"w\") as f:\n",
    "        for i in range(0, len(labels)):\n",
    "            for j in data[i]:\n",
    "                f.write(str(labels[i]) + \"\\t\" + str(j) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "labels, data = [*zip(*evars.items())]  # 'transpose' items to parallel key, value lists\n",
    "\n",
    "# or backwards compatible    \n",
    "#labels, data = dict1.keys(), dict1.values()\n",
    "\n",
    "plt.boxplot(data, showmeans=True)\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "#plt.ylim(bottom=-1, top = 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(alpha, mean(evars[alpha])) for alpha in evars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(alpha, median(evars[alpha])) for alpha in evars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data = [*zip(*sparsityH.items())]  # 'transpose' items to parallel key, value lists\n",
    "\n",
    "# or backwards compatible    \n",
    "#labels, data = dict1.keys(), dict1.values()\n",
    "\n",
    "plt.boxplot(data, showmeans=True)\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "#plt.ylim(bottom=-1, top = 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(alpha, mean(sparsityH[alpha])) for alpha in sparsityH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(alpha, median(sparsityH[alpha])) for alpha in sparsityH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, data = [*zip(*sparsityW.items())]  # 'transpose' items to parallel key, value lists\n",
    "\n",
    "# or backwards compatible    \n",
    "#labels, data = dict1.keys(), dict1.values()\n",
    "\n",
    "plt.boxplot(data, showmeans=True)\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "#plt.ylim(bottom=-1, top = 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(alpha, mean(sparsityW[alpha])) for alpha in sparsityW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(alpha, median(sparsityW[alpha])) for alpha in sparsityW]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best value of regularisation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0 not in evars:\n",
    "    raise Exception(\"Regularisation of 0 must be included to set threshold\")\n",
    "threshold = mean(evars[0]) - np.std(evars[0], ddof=1)\n",
    "print(mean(evars[0]), np.std(evars[0], ddof=1), threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the highest regularisation value greater than the threshold (obtained with regu = 0) \n",
    "regu_res = {i: None for i in range(2,11)}\n",
    "\n",
    "means_evars = {reg: mean(evars[reg]) for reg in evars}\n",
    "# values greater than threshold\n",
    "v = [i for i in means_evars.values() if i > threshold]\n",
    "# their associated keys\n",
    "k = [list(means_evars.keys())[list(means_evars.values()).index(i)] for i in v]\n",
    "\n",
    "\n",
    "print(max(k))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
